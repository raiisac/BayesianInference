---
documentclass: article
fontsize: 10pt
date: "`r Sys.Date()`"
output: 
  bookdown::pdf_document2: 
    fig_caption: yes
    toc: false
    latex_engine: xelatex
    includes:
      in_header: preamble.sty
      before_body: titlepage.sty
bibliography: references.bib  
---

```{r setup, include=FALSE, message=FALSE, warning=FALSE, appendix=TRUE}
#---------------------------load all packages----------------------------------#
library(tidyverse)
library(rprojroot)
library(kableExtra)
library('nimble')
library(coda)
library(cowplot)
library(latex2exp)

knitr::opts_chunk$set(echo = TRUE)
knitr::opts_knit$set(
  root.dir = find_root(criterion = has_file("BayesianInference.Rproj")))
```

# Task A: Cohort study smoking


:::: {.greybox data-latex=""}
::: {.center data-latex=""}
Abbott, Yin, Reed and Yano performed a 12-year cohort study to investigate
the association between smoking and stroke. Among 3435 smokers, 171 had
a stroke; while among 4437 non-smokers, 117 has a stroke.
:::

(1) Assuming a non-informative prior for the probability of disease among
those exposed $\theta_{+}$, give the analytical posterior for the probability of
disease among those exposed. Do the same for the probability of disease
among those not exposed $\theta_{-}$.
::::

In general, if $Y|\pi \sim Bin(n,\pi)$ is the data model and $\pi \sim Beta(\alpha, \beta)$ is the prior model, then the posterior model will be
$$\pi|y \sim Beta(\alpha + y, \beta + n-y)$$.

In the Beta distribution, there are several possibilities for uninformative priors [@tuyl2008comparison]. $\alpha=1, \beta=1$ generates an uniform probability density function. Jeffrey prior sets $\alpha=0.5, \beta=0.5$. And Kerman proposes to use a "Neutral" prior where $\alpha=\frac{1}{3}, \beta=\frac{1}{3}$ [@kerman2011neutral]. We will assume $\alpha=1, \beta=1$ which yields:

$$\pi|y \sim Beta(\alpha + y, \beta + n-y)$$
$$\pi|y \sim Beta(1 + 117, 1 + 4437-117)$$
$$\pi|y \sim Beta(118, 4321)$$.


:::: {.greybox data-latex=""}
(2) Give some summary measures of the above posterior distributions.
::::

The posterior expected value is 
$$E(\pi|y) = \frac{\alpha+y}{\alpha+\beta+n} = \frac{1+117}{1+1+4437} = 0.02658256$$
The posterior mode is   
$$Mode(\pi|y) = \frac{\alpha+y-1}{\alpha+\beta+n-2} = \frac{1+117-1}{1+1+4437-2} = 0.02636917$$

and the posterior variance is


$$Var(\pi|y) = \frac{(\alpha+y)(\beta+n-y)}{(\alpha+\beta+n)^2(\alpha+\beta+n+1)} = \frac{(1+117)(1+4437-117)}{(1+1+4437)^2(1+1+4437+1)} = 5.83 *10^{-6}$$

:::: {.greybox data-latex=""}
(3) Can you visualise the posterior distribution of the relative risk, defined as
$$\theta_{RR} = \frac{\theta_{+}}{\theta_{-}}$$
Use a sample from the above derived analytical posterior distribution to answer this question. Give some summary measures of the posterior distribution of the relative risk. Can you conclude that there is an association between smoking and stroke?
::::



:::: {.greybox data-latex=""}
(4) Write jags, OpenBugs or Nimble code, to obtain an MCMC samples
for the above problem.
::::

:::: {.greybox data-latex=""}
(5) Check convergence of the MCMC chain.
:::: 

:::: {.greybox data-latex=""}
(6) Compare the summary measures obtained from the MCMC chain with
the results obtained from questions (1)-(3).
:::: 

:::: {.greybox data-latex=""}
(7) What is the attributable risk of smoking to the incidence of stroke?
The attributable risk is defined as
$$\theta_{AR} = \frac{\theta_{RR}-1}{\theta_{RR}}$$
Extend your Bayesian MCMC code to derive the answer.
:::: 



# Task B: Dose-response model

```{r setup-taskB, include = FALSE, echo = FALSE, appendix = TRUE, cache = TRUE}
#------------------------------setup task B------------------------------------#
n <- 5
# Dose level
dose <- c(0,62.5,125,250,500)
# Number of fetus
N <- c(282,225,290,261,141)
# Number of malformations
y <- c(67,34,193,250,141)
#---------------------------------Question B1----------------------------------#
init1 <- list(alpha = 0, beta = 0)
init2 <- list(alpha = -0.5, beta = 0.1)
initial.values <- list(init1, init2)

# MCMC settings
n.iter <- 10000  # iterations
n.burnin <- 5000 # burn-in
n.chains <- 2    # chains

# Model settings
model.data <- list('dose' = dose, 'N' = N,'y' = y)
model.constant <- list('n' = n)

# Model 1
# A prior with Normal Distribution
model_1 <- nimbleCode({
  # Specify a vague prior with normal distribution
  alpha ~ dnorm(0, sd = 10000)
  beta ~ dnorm(0, sd = 10000)
  # likelihood
  for (i in 1:n) {
    logit(p[i]) <-  alpha + beta * dose[i]
    y[i] ~ dbin(p[i],N[i])
  }})

# Output of Model 1
mcmc.output1 <- nimbleMCMC(code = model_1,
                          data = model.data,
                          constants = model.constant,
                          inits = initial.values,
                          niter = n.iter,
                          nburnin = n.burnin,
                          summary = TRUE,
                          nchains = n.chains
)
```
:::: {.greybox data-latex=""}
(1) Assume that the likelihood of the experiment is specified by
$$y ∼ binomial(N, \pi)$$
$$logit(π) = α + βd.$$
Here $\beta$ is the parameter of interest. Take vague priors for $\alpha$ and $\beta$. Write jags, OpenBugs or Nimble code for this problem. Take 2 MCMC chains with different starting values, and check convergence with the appropriate techniques.
::::

To denote the uncertainty of parameters $\alpha$ and $\beta$, we specify two vague priors as a massive variance (extremely small precision) for these two parameters. The first vague prior is:
$$α \sim N(0,10000)$$
$$β \sim N(0,10000)$$

And the second vague prior is:
$$α \sim t(0,0.0001,5)$$
$$β \sim t(0,0.0001,5)$$
Our parameter settings include running 2 MCMC chains with different starting values for $\alpha$ and $\beta$. The first chain starts with ($\alpha=0$, $\beta=0$), while the second chain starts with ($\alpha=-0.5$,$\beta=0.1$). We run each chain for a total of 10000 iterations, with the first 5000 iterations used as a burn-in period. We will use Nimble for this task.

```{r echo=FALSE, include = FALSE, warning = FALSE, message = FALSE, appendix = TRUE}
# Trace plots
pdf("images/trace_normal.pdf") 
par(mfrow = c(2,2))
traceplot(as.mcmc(mcmc.output1$samples$chain1), xlab = "chain1$iteration")
traceplot(as.mcmc(mcmc.output1$samples$chain2), xlab = "chain2$iteration")
dev.off()
# Gelman-Rubin diagnostic plots
combinedchains1 = mcmc.list(as.mcmc(mcmc.output1$samples$chain1), as.mcmc(mcmc.output1$samples$chain2))
gelman.diag(combinedchains1)
pdf("images/gelman_normal.pdf") 
gelman.plot(combinedchains1,xlim = c(0,5000))
dev.off()
# Autocorrelation plots
par(mfrow = c(2, 2))
#densplot(as.mcmc(mcmc.output1$samples$chain1), main = "Chain1 Density of alpha")
#densplot(as.mcmc(mcmc.output1$samples$chain2), main = "Chain2 Density of alpha")
pdf("images/ac1_normal.pdf")
acf(as.mcmc(mcmc.output1$samples$chain1), xlab = 'Chain1 Lag')
dev.off()
pdf("images/ac2_normal.pdf")
acf(as.mcmc(mcmc.output1$samples$chain2), xlab = 'Chain2 Lag')
dev.off()
```

```{r trace-gelman-rubin-normal, echo=FALSE, warning = FALSE, message = FALSE, fig.cap = "Trace and Gelman-Rubin diagnostic plots of α and β (prior: normal distribution)", fig.show = "hold", out.width = "50%", fig.align = "default", appendix = FALSE}
knitr::include_graphics("images/trace_normal.pdf")
knitr::include_graphics("images/gelman_normal.pdf")
```


```{r acplot-normal, echo=FALSE, warning = FALSE, message = FALSE, appendix = FALSE, fig.cap = "Autocorrelation plots of α and β (prior: normal distribution)", fig.show = "hold", out.width = "50%", fig.align = "default"}
knitr::include_graphics("images/ac1_normal.pdf")
knitr::include_graphics("images/ac2_normal.pdf")
```


To assess the convergence of the model with a prior normal distribution, we employed several diagnostic tools including trace plots, the Gelman-Rubin diagnostic test, and autocorrelation plots. 
We observed from the trace plots of $\alpha$ and $\beta$ (refer to Figure \@ref(fig:trace-gelman-rubin-normal)) that the estimates from each chain quickly stabilized around a steady state. Additionally, both chains were found to converge around the same conclusion. Furthermore, we conducted the Gelman-Rubin diagnostic test, which showed that the estimated potential scale reduction factors of $\alpha$ and $\beta$ were both 1. These results suggest that our model has converged well. Moreover, the Gelman-Rubin diagnostic plots (refer to Figure \@ref(fig:trace-gelman-rubin-normal)) support this conclusion, as both the potential scale reduction factors of $\alpha$ and $\beta$ were found to decrease quickly and remain stable as the number of iterations increased. We also examined the autocorrelation plots (refer to Figure \@ref(fig:acplot-normal)), which indicated low autocorrelation. The autocorrelation decreased and remained around zero as the lag number increased, indicating that the chains have mixed well.
Overall, these diagnostic tools suggest that our model that the prior is normal distribution has converged well, and the inference based on the Markov chain Monte Carlo simulation is reliable.

```{r cache = TRUE, echo = FALSE, message = FALSE, warning = FALSE, appendix = TRUE, include = FALSE}
# Model 2
# A prior with t Distribution
model_2 <- nimbleCode({
  # Specify a vague prior with t distribution
  alpha ~ dt(0, 0.0001, 5)
  beta ~ dt(0, 0.0001, 5)
  # likelihood
  for (i in 1:n) {
    logit(p[i]) <-  alpha + beta * dose[i]
    y[i] ~ dbin(p[i],N[i])
  }})

# Output of Model 1
mcmc.output2 <- nimbleMCMC(code = model_2,
                           data = model.data,
                           constants = model.constant,
                           inits = initial.values,
                           niter = n.iter,
                           nburnin = n.burnin,
                           summary = TRUE,
                           nchains = n.chains
)

# Trace plots
pdf("images/trace_t.pdf") 
par(mfrow = c(2,2))
traceplot(as.mcmc(mcmc.output2$samples$chain1), xlab = "chain1$iteration")
traceplot(as.mcmc(mcmc.output2$samples$chain2), xlab = "chain2$iteration")
dev.off()
# Autocorrelation plots
par(mfrow = c(2,2))
densplot(as.mcmc(mcmc.output2$samples$chain1), main = "Chain1 Density of alpha")
densplot(as.mcmc(mcmc.output2$samples$chain2), main = "Chain2 Density of alpha")

pdf("images/ac1_t.pdf") 
acf(as.mcmc(mcmc.output2$samples$chain1), xlab = 'Chain1 Lag')
dev.off()
pdf("images/ac2_t.pdf") 
acf(as.mcmc(mcmc.output2$samples$chain2), xlab = 'Chain2 Lag')
dev.off()
# Gelman-Rubin diagnostic plots
combinedchains2 = mcmc.list(as.mcmc(mcmc.output2$samples$chain1), as.mcmc(mcmc.output2$samples$chain2))
gelman.diag(combinedchains2)
pdf("images/gelman_t.pdf")
gelman.plot(combinedchains2,xlim = c(0,5000))
dev.off()
```

```{r trace-gelman-rubin-t, echo=FALSE, warning = FALSE, message = FALSE, fig.cap = "Trace and Gelman-Rubin diagnostic plots of α and β (prior: t-distribution)", fig.show = "hold", out.width = "50%", fig.align = "default", appendix = FALSE}
knitr::include_graphics("images/trace_t.pdf")
knitr::include_graphics("images/gelman_t.pdf")
```


```{r acplot-t, echo=FALSE, warning = FALSE, message = FALSE, appendix = FALSE, fig.cap = "Autocorrelation plots of α and β (prior: t-distribution)", fig.show = "hold", out.width = "50%", fig.align = "default"}
knitr::include_graphics("images/ac1_t.pdf")
knitr::include_graphics("images/ac2_t.pdf")
```
  
We analyzed the convergence of the model with a prior t-distribution using trace plots, autocorrelation plots, and Gelman-Rubin diagnostic plots, which are presented in Figure \@ref(fig:trace-gelman-rubin-t) and Figure \@ref(fig:acplot-t). We observed that all the trends remained consistent with the plots obtained using a normal distribution for $\alpha$ and $\beta$. Moreover, the estimated potential scale reduction factors of $\alpha$ and $\beta$ were found to be equal to 1, indicating good convergence of the model. These results provide compelling evidence that the model with a prior t-distribution has achieved good convergence and that the inference derived from the Markov chain Monte Carlo simulation is reliable.



:::: {.greybox data-latex=""}
(2) Summarize all results graphically and summarize with the usual Bayesian posterior measures. What do you conclude from these?
::::


```{r b2fig, echo=FALSE, warning = FALSE, message = FALSE, appendix = TRUE, fig.cap = "Density plots of α and β with normal distribution (top) and t distribution (bottom).", fig.width=6, fig.height=4}
#--------------------------------Question B2-----------------------------------#
par(mfrow = c(2,2))
densplot(as.mcmc(mcmc.output1$samples$chain1,mcmc.output1$samples$chain2))
densplot(as.mcmc(mcmc.output2$samples$chain1,mcmc.output2$samples$chain2))
```

The density plots with a normal distributed prior and a t distributed prior, as presented in Figure \@ref(fig:b2fig). The plots for both $\alpha$ and $\beta$ display smooth distributions with similar mean values, suggesting that both priors lead to similar approximations of the true posterior distribution.

```{r b2, cache = TRUE, echo = FALSE, message = FALSE, warning = FALSE, appendix = TRUE, include = TRUE}
# Normal distribution
#mcmc.output1$summary 
samples_n <- rbind(mcmc.output1$samples$chain1,mcmc.output1$samples$chain2)
HPD1 <- as.data.frame(round(HPDinterval(as.mcmc(samples_n)),3)) %>%
  mutate(interval = paste0("[", lower, ", ", upper, "]"))

# t distribution
#mcmc.output2$summary 
samples_t <- rbind(mcmc.output2$samples$chain1,mcmc.output2$samples$chain2)
HPD2 <- as.data.frame(round(HPDinterval(as.mcmc(samples_t)),3)) %>%
  mutate(interval = paste0("[", lower, ", ", upper, "]"))

as.data.frame(rbind(mcmc.output1$summary$all.chains[, -c(4, 5)],
                    mcmc.output2$summary$all.chains[, -c(4, 5)])) %>%
  mutate(HPD = c(HPD1$interval, HPD2$interval)) %>%
  kable(booktabs = TRUE,
        caption = "Bayesian posterior measures of α and β",
        col.names = c("Mean", "Median", "St.Dev", "HPD Interval")) %>%
  kableExtra::group_rows(group_label = "N(0, 10000)",
                         start_row = 1, end_row = 2) %>%
  kableExtra::group_rows(group_label = "t(0, 0.0001, 5)",
                         start_row = 3, end_row = 4)
```

Based on the Bayesian posterior measures of α and β (Table \@ref(tab:b2)), it can be concluded that the probability of malformations is ?????0.143????? in the absence of any administered dose. As the dose increases, the probability of malformations also increases, indicating a positive dose-response relationship. Additionally, the 95% highest posterior density (HPD) interval, which captures the 95% most plausible parameter values, does not include the value of 0, providing evidence for the existence of a dose effect.

:::: {.greybox data-latex=""}
(3) Plot the posterior dose-response relationship together with the observed probabilities of a malformation per dose.
::::

```{r b3, echo=FALSE, warning = FALSE, message = FALSE, appendix = TRUE, fig.cap = "Posterior dose-response relationship and observed probabilities.", fig.width=4, fig.height=3}
#--------------------------------Question B3-----------------------------------#
# posterior with normal distribution
chains_output1 <- data.frame(mcmc.output1[[1]])
chain1_output1 <- chains_output1[, 1:2] %>%
  rename("alpha" = "chain1.alpha", "beta" = "chain1.beta")
chain2_output1 <- chains_output1[, 3:4] %>%
  rename("alpha" = "chain2.alpha", "beta" = "chain2.beta")
df_output1 <- rbind(chain1_output1, chain2_output1)
# get the mean value of alpha and beta
alpha_n <- round(mean(df_output1$alpha), 3)
beta_n <- round(mean(df_output1$beta), 3)

# posterior with t distribution
chains_output2 <- data.frame(mcmc.output2[[1]])
chain1_output2 <- chains_output2[, 1:2] %>%
  rename("alpha" = "chain1.alpha", "beta" = "chain1.beta")
chain2_output2 <- chains_output2[,3:4] %>%
  rename("alpha" = "chain2.alpha", "beta" = "chain2.beta")
df_output2 <- rbind(chain1_output2, chain2_output2)
# get the mean value of alpha and beta
alpha_t <- round(mean(df_output2$alpha), 3)
beta_t <- round(mean(df_output2$beta), 3)

# Create a dataframe for plotting
df_plotting <- data.frame(cbind(dose,N,y)) %>%
  mutate(prob_observed = y/N,# Observed
         prob_n = expit(alpha_n + beta_n * dose),# Posterior with normal distr
         prob_t = expit(alpha_t + beta_t * dose)# Posterior with t distr
         )

ggplot(df_plotting, aes(x = dose)) +
  geom_line(aes(y = prob_observed, color = "Observed")) +
  geom_line(aes(y = prob_n, color = "Posterior(normal distribution)")) +
  geom_line(aes(y = prob_t, color = "Posterior(t distribution)"),
            linetype = "dashed", linewidth = 1) +
  labs(x = "Dose", y = "Probability", color = "") +
  theme_bw() +
  theme(legend.position = c(0.65, 0.25))
```

Figure \@ref(fig:b3) indicates that the trends in the posteriors exhibit a dose-response relationship that is similar to the observed probabilities, with the exception of the dose range of 50-70. Moreover, the posterior with t-distributed priors closely aligns with the posterior with normal distributed priors. In general, all three lines demonstrate an increasing probability of malformations as the dose increases, with this increase leveling off as the dose approaches approximately 400.


:::: {.greybox data-latex=""}
(4) A safe level of exposure can be defined as a dose corresponding to a very small increase in excess risk of q, e.g. q = 0.05. This is called the Benchmark dose (BMD) $d^∗$ and can be obtained by solving the equation
$$r(d^*) = \frac{P(d^*) − P(0)}{1 − P(0)} = q$$
with $P(d)$ the probability of an adverse effect at dose level d. For a logistic regression with a linear dose model, the BMD is given by 
$$BMD = \frac{logit(q^*) − \alpha}{\beta}$$
with $q^* = q(1 − P(0)) + P(0)$. Determine the posterior estimate of the safe level of exposure for DYME corresponding with an excess risk of $q$ = 0.05.
::::

```{r b4, cache = TRUE, echo = FALSE, message = FALSE, warning = FALSE, appendix = TRUE, include = TRUE}
#--------------------------------Question B4-----------------------------------#
# Excess risk q=0.05
# prior Normal distribution
df_output1_bmd <- df_output1 %>%
  # Caculate BMD
  mutate(P0 = exp(alpha) / (1 + exp(alpha))) %>%
  mutate(q.star = (0.05 * (1 - P0)) + P0) %>%
  mutate(bmd = (logit(q.star) - alpha) / beta)

# HPD Interval
hpd_n <- as.data.frame(round(HPDinterval(as.mcmc(df_output1_bmd)), 3)) %>%
  mutate(interval = paste0("[", lower, ", ", upper, "]"))

# prior t distribution
df_output2_bmd <- df_output2 %>%
  # Caculate BMD
  mutate(P0 = exp(alpha) / (1 + exp(alpha))) %>%
  mutate(q.star = (0.05 * (1 - P0)) + P0) %>%
  mutate(bmd = (logit(q.star) - alpha) / beta)
# HPD Interval
hpd_t <- as.data.frame(round(HPDinterval(as.mcmc(df_output2_bmd)), 3)) %>%
  mutate(interval = paste0("[", lower, ", ", upper, "]"))

data.frame(Prior = c("Normal distribution", "t-distribution"),
           mean = c(round(mean(df_output1_bmd$bmd), 3),
                    round(mean(df_output2_bmd$bmd), 3)),
           hpd = c(hpd_n[5, "interval"], hpd_t[5, "interval"])) %>%
  kable(booktabs = TRUE,
        col.names = c("BMD (Mean)", "HPD interval", "Prior"),
        caption = "Posterior measures of BMD.") %>%
  kableExtra::kable_styling()
```

The posterior mean values for BMD and the corresponding HPD interval are shown in Table \@ref(tab:b4). The lower bounds of the HPD interval for the prior normal distribution (`r hpd_n[5, "upper"]` for Normal distribution and `r hpd_t[5, "upper"]` for t-distribution) should be considered as the Benchmark does.

:::: {.greybox data-latex=""}
(5) As an alternative, a safe level of exposure can be obtained from a threshold model, defined as
$$y ∼ binomial(N, \pi)$$
$$logit(\pi) = \alpha + \beta(d − \tau)I(d > \tau)$$,
with $\tau$ the threshold dose below which there is no excess risk. Write code for this model, and summarize the results. How do these results compare with previous results?
::::

In this threshold model, we essentially fit a piecewise linear regression for $logit(\pi)$:

- if the dose is smaller than $\tau$, $I(d<\tau)=0$ meaning the intercept is $\alpha$ and the slope is zero.
- if the dose is larger than $\tau$, $I(d<\tau)=1$ meaning the intercept is $\alpha -\beta\tau$ and the slope is $\beta$

We will use the same vague priors from a Normal distribution:
$$α \sim N(0,10000)$$
$$β \sim N(0,10000)$$
All other tuning parameter such as initial values and burn-in are chosen the same as in the previous model. We will test several models with $\tau \in \{0,62.5,125,250,500\}$. We will select the model that minimises the WAIC. 

```{r, echo=FALSE, message=FALSE, warning=FALSE, eval= !file.exists("output/results_threshold_model.Rdata"), appendix=TRUE}
#---------------------------Question B-----------------------------------------#
#possibly interesting reference for piecewise linear regression in R with nimble
#https://gkonstantinoudis.github.io/nimble/PiecewiseLinear.html 
init1 <- list(alpha = 0, beta = 0)
init2 <- list(alpha = -0.5, beta = 0.1)
initial.values <- list(init1, init2)

# MCMC settings
n.iter <- 10000  # iterations
n.burnin <- 5000 # burn-in
n.chains <- 2    # chains


testmodel <- function(tau = 0){
  # Model settings
  indicator <- 1*(dose > tau)
  model.data <- list('dose' = dose, 'N' = N,'y' = y, 'indicator' = indicator)
  model.constant <- list('n' = n)

  # Model 1
  # A prior with Normal Distribution
  model <- nimbleCode({
    # Specify a vague prior with normal distribution
    alpha ~ dnorm(0, sd = 10000)
    beta ~ dnorm(0, sd = 10000)
    # likelihood
    for (i in 1:n) {
      logit(p[i]) <-  alpha + beta * dose[i] * indicator[i]
      y[i] ~ dbin(p[i],N[i])
    }})

  # Output of Model 1
  mcmc.output <- nimbleMCMC(code = model,
                            data = model.data,
                            constants = model.constant,
                            inits = initial.values,
                            niter = n.iter,
                            nburnin = n.burnin,
                            summary = TRUE,
                            nchains = n.chains,
                            WAIC = TRUE
  )
  return(mcmc.output)
}
tau_values <- c(0,62.5,125,250,500)
results <- map(tau_values, testmodel)
save(results, file = "output/results_threshold_model.Rdata")
waic <- sapply(X = seq(length(tau_values)),
      FUN = function(x) {results[[x]]$WAIC$WAIC})
```

```{r, echo=FALSE, message=FALSE, warning=FALSE, eval= file.exists("output/results_threshold_model.Rdata"), appendix=FALSE}
tau_values <- c(0,62.5,125,250,500)
load("output/results_threshold_model.Rdata")
waic <- sapply(X = seq(length(tau_values)),
      FUN = function(x) {results[[x]]$WAIC$WAIC})
```

Figure \@ref(fig:threshold-WAIC) shows that the lowest WAIC is reached when $\tau=$ `r tau_values[which(waic == min(waic))]`. This means that, for doses $\leq$ `r tau_values[which(waic == min(waic))]`, $logit(\pi)=\alpha$, independent of the dose. For doses $>$ `r tau_values[which(waic == min(waic))]`, $logit(\pi)=\alpha + \beta(d-$ `r tau_values[which(waic == min(waic))]` $)$. 

(ref:threshold-WAIC) WAIC for each value of $\tau$.

```{r threshold-WAIC, echo=FALSE, message=FALSE, warning=FALSE, appendix=TRUE, fig.cap = "(ref:threshold-WAIC)",fig.height=3, fig.width=4}
#plot the relationship between WAIC and tau
data.frame(waic = waic,
           tau = tau_values) %>%
  ggplot(aes(x = tau, y = waic)) + 
  geom_point() + 
  geom_line() +
  theme_bw() +
  ylab("WAIC") + xlab(TeX("$\\tau$")) + 
  geom_vline(aes(xintercept = tau_values[which(waic == min(waic))]),
             linetype = "dashed") +
  scale_x_continuous(breaks = tau_values)

chosen_model <- results[[which(waic == min(waic))]]
```

For the model with the lowest WAIC, we observe from the trace plots of $\alpha$ and $\beta$ (refer to Figure \@ref(fig:trace-gelman-rubin-threshold)) that the estimates from each chain quickly stabilized around a steady state. Additionally, both chains were found to converge around the same conclusion. The Gelman-Rubin diagnostic test showed that the estimated potential scale reduction factors of $\alpha$ and $\beta$ were both 1. These results suggest that our model has converged well. Moreover, the Gelman-Rubin diagnostic plots (Figure \@ref(fig:trace-gelman-rubin-threshold)) support this conclusion, as both the potential scale reduction factors of $\alpha$ and $\beta$ were found to decrease quickly and remain stable as the number of iterations increased. We also examined the autocorrelation plots (refer to Figure \@ref(fig:acplot-threshold)), which indicated low autocorrelation. The autocorrelation decreased and remained around zero as the lag number increased, indicating that the chains have mixed well.
Overall, these diagnostic tools suggest that our model that the has converged well, and the inference based on the Markov chain Monte Carlo simulation is reliable.

```{r echo=FALSE, include = FALSE, warning = FALSE, message = FALSE, appendix = TRUE}
# Trace plots
pdf("images/trace_threshold.pdf") 
par(mfrow = c(2,2))
traceplot(as.mcmc(chosen_model$samples$chain1), xlab = "chain1$iteration")
traceplot(as.mcmc(chosen_model$samples$chain2), xlab = "chain2$iteration")
dev.off()
# Gelman-Rubin diagnostic plots
combinedchains1 = mcmc.list(as.mcmc(chosen_model$samples$chain1),
                            as.mcmc(chosen_model$samples$chain2))
gelman.diag(combinedchains1)
pdf("images/gelman_threshold.pdf") 
gelman.plot(combinedchains1,xlim = c(0,5000))
dev.off()
# Autocorrelation plots
par(mfrow = c(2, 2))
pdf("images/ac1_threshold.pdf")
acf(as.mcmc(chosen_model$samples$chain1), xlab = 'Chain1 Lag')
dev.off()
pdf("images/ac2_threshold.pdf")
acf(as.mcmc(chosen_model$samples$chain2), xlab = 'Chain2 Lag')
dev.off()
```

```{r trace-gelman-rubin-threshold, echo=FALSE, warning = FALSE, message = FALSE, fig.cap = "Trace and Gelman-Rubin diagnostic plots of α and β for the threshold model with the lowest WAIC.", fig.show = "hold", out.width = "50%", fig.align = "default", appendix = FALSE}
knitr::include_graphics("images/trace_threshold.pdf")
knitr::include_graphics("images/gelman_threshold.pdf")
```


```{r acplot-threshold, echo=FALSE, warning = FALSE, message = FALSE, appendix = FALSE, fig.cap = "Autocorrelation plots of α and β for the threshold model with the lowest WAIC.", fig.show = "hold", out.width = "50%", fig.align = "default"}
knitr::include_graphics("images/ac1_threshold.pdf")
knitr::include_graphics("images/ac2_threshold.pdf")
```


```{r density-threshold, echo=FALSE, warning = FALSE, message = FALSE, appendix = TRUE, fig.cap = "Density plots of α and β for the threshold model with the lowest WAIC.", fig.width=6, fig.height=3}
par(mfrow = c(1,2))
densplot(as.mcmc(chosen_model$samples$chain1,chosen_model$samples$chain2))
```

The density plots are presented in Figure \@ref(fig:density-threshold). The plots for both $\alpha$ and $\beta$ display smooth distributions. Table \@ref(tab:b2-threshold) summarizes the posterior measures of $\alpha$ and $\beta$.

```{r b2-threshold, cache = TRUE, echo = FALSE, message = FALSE, warning = FALSE, appendix = TRUE, include = TRUE}
samples_n <- rbind(chosen_model$samples$chain1,chosen_model$samples$chain2)
HPD1 <- as.data.frame(round(HPDinterval(as.mcmc(samples_n)),3)) %>%
  mutate(interval = paste0("[", lower, ", ", upper, "]"))

as.data.frame(chosen_model$summary$all.chains[, -c(4, 5)]) %>%
  mutate(HPD = HPD1$interval) %>%
  kable(booktabs = TRUE,
        caption = "Bayesian posterior measures of α and β",
        col.names = c("Mean", "Median", "St.Dev", "HPD Interval")) %>%
  kableExtra::kable_styling()
```


Figure \@ref(fig:threshold-posterior-fit) shows that the fit of the posterior dose-response relationship  with the observed probabilities improved combared to Figure \@ref(fig:b3), especially in the range with lower doses.

```{r threshold-posterior-fit, echo=FALSE, message=FALSE, warning=FALSE, appendix=TRUE, fig.cap="Posterior dose-response relationship and observed probabilities for the model with the lowest WAIC.", fig.height=3, fig.width=4}
#plot posterior vs observed probabilities
chains_output1 <- data.frame(chosen_model[[1]])
chain1_output1 <- chains_output1[, 1:2] %>%
  rename("alpha" = "chain1.alpha", "beta" = "chain1.beta")
chain2_output1 <- chains_output1[, 3:4] %>%
  rename("alpha" = "chain2.alpha", "beta" = "chain2.beta")
df_output1 <- rbind(chain1_output1, chain2_output1)
# get the mean value of alpha and beta
alpha_n <- round(mean(df_output1$alpha), 3)
beta_n <- round(mean(df_output1$beta), 3)

# Create a dataframe for plotting
df_plotting <- data.frame(cbind(dose, N, y)) %>%
  mutate(indicator = 1*(dose > tau_values[which(waic == min(waic))]),
         prob_observed = y/N,
         threshold_model = expit(alpha_n + beta_n * dose * indicator)
         )
ggplot(df_plotting, aes(x = dose)) +
  geom_line(aes(y = prob_observed, color = "Observed")) +
  geom_line(aes(y = threshold_model, color = "Threshold model"), linetype = "dashed") +
  theme_bw() +
  theme(legend.position = c(0.7, 0.2)) +
  scale_color_discrete("") +
  ylab("Probability") +
  xlab("Dose")
  
```

\clearpage


\appendix

# Appendix

## All code for the report

\small

```{r get-labels, echo = FALSE}
#all code that needs to be in the appendix needs to have appendix = TRUE
labs = knitr::all_labels(appendix == TRUE)
labs = setdiff(labs, c("get-labels"))
```

```{r all-code, ref.label=labs, eval=FALSE}
```

\normalsize
\clearpage



# Bibliography
